{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bdc3be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Collect data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sodapy import Socrata\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "client = Socrata(\"data.cityofnewyork.us\", \"40p3Q4A72d009q4eGhZThIOyP\")\n",
    "query = (\"SELECT * \"\n",
    "         \"WHERE cmplnt_fr_dt >= '2021-01-01T00:00:00.000' \"\n",
    "         \"AND cmplnt_fr_dt < '2023-01-01T00:00:00.000' \"\n",
    "         \"LIMIT 1000000\")\n",
    "results = client.get(\"qgea-i56i\", query = query)\n",
    "results_df = pd.DataFrame.from_records(results)\n",
    "results_df.to_csv('NYC_Crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3236e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean data\n",
    "\n",
    "# Remove unnecessary columns\n",
    "results_df = results_df.drop(['cmplnt_num', 'addr_pct_cd', 'rpt_dt', 'ky_cd', 'pd_cd', 'pd_desc', 'law_cat_cd', \n",
    "                              'latitude', 'longitude', 'lat_lon', 'cmplnt_to_dt', 'cmplnt_to_tm', 'parks_nm', 'hadevelopt', \n",
    "                              'housing_psa', 'station_name', 'transit_district', 'crm_atpt_cptd_cd', 'patrol_boro',\n",
    "                              'boro_nm', 'loc_of_occur_desc', 'prem_typ_desc', 'juris_desc', 'susp_age_group',\n",
    "                              'vic_age_group'], axis = 1)   \n",
    "\n",
    "# Combine similar crimes\n",
    "results_df.loc[results_df['ofns_desc'].str.contains('ASSAULT', na=False ), 'ofns_desc'] = 'VIOLENT CRIMES'\n",
    "results_df.loc[results_df['ofns_desc'].str.contains('ROBBERY', na=False ), 'ofns_desc'] = 'VIOLENT CRIMES'\n",
    "\n",
    "results_df.loc[results_df['ofns_desc'].str.contains('GRAND LARCENY', na=False ), 'ofns_desc'] = 'PROPERTY CRIMES'\n",
    "results_df.loc[results_df['ofns_desc'].str.contains('THEFT', na=False ), 'ofns_desc'] = 'PROPERTY CRIMES' \n",
    "results_df.loc[results_df['ofns_desc'].str.contains('MISCHIEF', na=False ), 'ofns_desc'] = 'PROPERTY CRIMES' \n",
    "\n",
    "#Convert to date_time variable\n",
    "results_df['cmplnt_fr_dt'] = pd.to_datetime(results_df['cmplnt_fr_dt'], format='%Y-%m-%dT%H:%M:%S.%f', errors = 'coerce').dt.date\n",
    "results_df = results_df.dropna()\n",
    "results_df['date_time'] = pd.to_datetime(results_df['cmplnt_fr_dt'].astype(str) + ' ' + results_df['cmplnt_fr_tm'].astype(str))\n",
    "results_df.insert(results_df.columns.get_loc('cmplnt_fr_tm')+1, 'date_time', results_df.pop('date_time'))\n",
    "results_df = results_df.drop(['cmplnt_fr_dt', 'cmplnt_fr_tm'], axis=1)\n",
    "\n",
    "# Extract year, season, month, day, day of the week, and hour\n",
    "results_df['year'] = results_df['date_time'].dt.year\n",
    "results_df['quarter'] = results_df['date_time'].dt.quarter\n",
    "results_df['month'] = results_df['date_time'].dt.month\n",
    "results_df['day'] = results_df['date_time'].dt.day\n",
    "results_df['day_of_week'] = results_df['date_time'].dt.dayofweek\n",
    "results_df['hour'] = results_df['date_time'].dt.hour\n",
    "results_df = results_df.drop(['date_time'], axis = 1)\n",
    "results_df = results_df.replace('(null)',np.nan).dropna(axis = 0, how = 'any')\n",
    "\n",
    "#Remove outliers\n",
    "results_df = results_df.groupby('vic_sex').filter(lambda x : len(x)>100000)\n",
    "results_df = results_df.groupby('vic_race').filter(lambda x : len(x)>100000)\n",
    "results_df = results_df.groupby('susp_race').filter(lambda x : len(x)>100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d31ba1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Show dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e78144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "\n",
    "# Convert numeric values into int32 data types\n",
    "results_df['jurisdiction_code'] = results_df['jurisdiction_code'].astype('int32')\n",
    "results_df['x_coord_cd'] = results_df['x_coord_cd'].astype('int32')\n",
    "results_df['y_coord_cd'] = results_df['y_coord_cd'].astype('int32')\n",
    "results_df['year'] = results_df['year'].astype('int32')\n",
    "results_df['quarter'] = results_df['quarter'].astype('int32')\n",
    "results_df['month'] = results_df['month'].astype('int32')\n",
    "results_df['day'] = results_df['day'].astype('int32')\n",
    "results_df['day_of_week'] = results_df['day_of_week'].astype('int32')\n",
    "results_df['hour'] = results_df['hour'].astype('int32')\n",
    "\n",
    "# Filter violent and property crimes into separate dataframe\n",
    "new_data = results_df.loc[(results_df['ofns_desc'] == 'VIOLENT CRIMES') | (results_df['ofns_desc'] == 'PROPERTY CRIMES')]\n",
    "new_data = new_data.drop_duplicates()\n",
    "\n",
    "# Create new \n",
    "X = new_data.drop(['ofns_desc'], axis=1)\n",
    "y = new_data['ofns_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15ad570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for unbalanced data\n",
    "new_data['ofns_desc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f63ce58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c44be1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More preprocessing!\n",
    "\n",
    "# Encode categorical values for training set\n",
    "X_train_categorical = []\n",
    "categorical_train_cols = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "X_train_categorical = X_train[categorical_train_cols]\n",
    "X_train_numeric = X_train.select_dtypes(exclude=['object', 'category'])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')  \n",
    "\n",
    "X_train_categorical = encoder.fit_transform(X_train_categorical)\n",
    "X_train_numeric.reset_index(drop=True, inplace=True)\n",
    "X_train_encoded = pd.concat([pd.DataFrame(X_train_categorical, columns=encoder.get_feature_names_out(input_features=categorical_train_cols)), X_train_numeric], axis=1)\n",
    "\n",
    "# Encode categorical values for test set\n",
    "X_test_categorical = []\n",
    "categorical_test_cols = X_test.select_dtypes(include=['object', 'category']).columns\n",
    "X_test_categorical = X_test[categorical_test_cols]\n",
    "X_test_numeric = X_test.select_dtypes(exclude=['object', 'category'])\n",
    "\n",
    "X_test_categorical = encoder.transform(X_test_categorical)\n",
    "X_test_numeric.reset_index(drop=True, inplace=True)\n",
    "X_test_encoded = pd.concat([pd.DataFrame(X_test_categorical, columns=encoder.get_feature_names_out(input_features=categorical_test_cols)), X_test_numeric], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867bbfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "\n",
    "# Instantiate random forest model with hyperparameters\n",
    "rfc = RandomForestClassifier(n_estimators = 171, min_samples_split = 8, min_samples_leaf = 2, max_depth = 110, bootstrap = True)\n",
    "rfc.fit(X_train_encoded, y_train)\n",
    "y_pred_proba = rfc.predict_proba(X_test_encoded)\n",
    "\n",
    "# Get the probabilities for the positive class\n",
    "positive_class_probs = y_pred_proba[:, 1]\n",
    "\n",
    "# Set the threshold for the positive class\n",
    "threshold = 0.463\n",
    "\n",
    "# Adjust the predictions based on the threshold\n",
    "y_pred_adjusted = (positive_class_probs >= threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a67a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics for the performance of the model \n",
    "\n",
    "# Convert string labels to numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test_encoded, y_pred_adjusted)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "plt.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10}, cmap=plt.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['Violent Crimes', 'Property Crimes']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "plt.xticks(tick_marks, class_names, rotation=25)\n",
    "plt.yticks(tick_marks2, class_names, rotation=0)\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.title('Confusion Matrix for Random Forest Model')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test_encoded, y_pred_adjusted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e9c5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View ROC curve to find optimal threshold \n",
    "\n",
    "# Calculate the FPR, TPR, and thresholds for the ROC curve\n",
    "predicted_probabilities = rfc.predict_proba(X_test_encoded)\n",
    "\n",
    "# Extract the probabilities for the positive class\n",
    "positive_probs = predicted_probabilities[:, 1]\n",
    "\n",
    "# Calculate the False Positive Rate (FPR), True Positive Rate (TPR), and thresholds for the ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test_encoded, positive_probs)\n",
    "\n",
    "auc = roc_auc_score(y_test_encoded, positive_probs)\n",
    "print(\"AUC: %.3f\" % auc)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, label='ROC curve')\n",
    "\n",
    "# Draw the diagonal line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Draw the diagonal line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Calculate the threshold value\n",
    "threshold = thresholds[np.argmax(tpr-fpr)]\n",
    "print(\"Threshold: %.3f\" % threshold)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5ba3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph importance scores of features for feature selection\n",
    "\n",
    "# Get scores\n",
    "feature_scores = pd.Series(rfc.feature_importances_, index=X_train_encoded.columns).sort_values(ascending=False).head(10)\n",
    "\n",
    "# Create bar plot for scores\n",
    "sns.barplot(x=feature_scores, y=feature_scores.index)\n",
    "\n",
    "# Add labels to the graph\n",
    "plt.xlabel('Feature Importance Score')\n",
    "plt.ylabel('Features')\n",
    "\n",
    "# Add title to the graph\n",
    "plt.title(\"Visualizing Important Features\")\n",
    "\n",
    "# Visualize the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adc310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning hyperparameters\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [int(x) for x in np.linspace(1, 250, num=20)],\n",
    "    'max_depth': [int(x) for x in np.linspace(10, 110, num = 11)],\n",
    "    'min_samples_split': list(range(1, 10)),\n",
    "    'min_samples_leaf': list(range(1, 5)),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rs = RandomForestClassifier()\n",
    "random_search = RandomizedSearchCV(rs, param_distributions = parameters, n_iter=5, cv=5) \n",
    "random_search.fit(X_train_encoded, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c5a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best score:', random_search.best_score_)\n",
    "print('Best params:', random_search.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "fa1c5bc318ffa87759a37cf287c5176fe5b890d4e91d328d205addbf5554b247"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
